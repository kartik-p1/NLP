{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "matra_of_vowels = {'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॄ', 'ॅ', 'े', 'ै', 'ो', 'ौ', 'ं', 'ः', 'ँ'}\n",
    "\n",
    "# Set containing Hindi vowels\n",
    "hindi_vowels = {'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ए', 'ऐ', 'ओ', 'औ', 'अं', 'अः', 'अँ'}\n",
    "\n",
    "# Set containing Hindi consonants\n",
    "hindi_consonants = {'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', \n",
    "                    'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'व', \n",
    "                    'श', 'ष', 'स', 'ह', 'क्ष', 'त्र', 'ज्ञ'}\n",
    "halant = \"्\"\n",
    "def clean_token(tokens1):\n",
    "    tokens = []\n",
    "    for word in tokens1:\n",
    "        s=\"\"\n",
    "        for c in word:\n",
    "            if (c not in matra_of_vowels) and (c not in hindi_consonants) and (c not in hindi_vowels) and c != halant: continue\n",
    "            else: s = s + c\n",
    "        if(len(s)): tokens.append(s)\n",
    "    return tokens\n",
    "# //remove white space\n",
    "def clean_white_space(tokens):\n",
    "    ans = []\n",
    "    for token in tokens:\n",
    "        # token.lstrip()\n",
    "        ans.append(token)\n",
    "        # print(token)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load the IndicBERT tokenizer\n",
    "tokenizer_indic_bert = AutoTokenizer.from_pretrained(\"ai4bharat/indic-bert\")\n",
    "\n",
    "# Define the input sentence\n",
    "sentence = \"तुम्हारे पास क्या है?\"\n",
    "with open('hi_100.txt', 'r', encoding='utf-8') as file:\n",
    "    # Read the entire content of the file\n",
    "    corpus = file.read()\n",
    "\n",
    "\n",
    "# Tokenize the sentence\n",
    "tokens = tokenizer_indic_bert.tokenize(tokenizer_indic_bert.decode(tokenizer_indic_bert.encode(corpus, max_length=1000, truncation=True)))\n",
    "tokens = clean_token(tokens)\n",
    "# Print the tokens\n",
    "# print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m letter_freq_map \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m----> 2\u001b[0m tokens \u001b[38;5;241m=\u001b[39m clean_token(\u001b[43mtokens\u001b[49m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m letter \u001b[38;5;129;01min\u001b[39;00m tokens:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m letter \u001b[38;5;129;01min\u001b[39;00m letter_freq_map:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokens' is not defined"
     ]
    }
   ],
   "source": [
    "letter_freq_map = {}\n",
    "tokens = clean_token(tokens)\n",
    "for letter in tokens:\n",
    "\n",
    "    if letter in letter_freq_map:\n",
    "        letter_freq_map[letter] += 1\n",
    "    else:\n",
    "        letter_freq_map[letter] = 1\n",
    "\n",
    "sorted_freq_items = sorted(letter_freq_map.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_freq_items = sorted_freq_items[:20]\n",
    "# Print the sorted frequencies\n",
    "print(\"Top 20 tokens\")\n",
    "for letter, freq in sorted_freq_items:\n",
    "    print(letter, \":\", freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "अ : 78\n",
      "आ : 38\n",
      "क् : 18\n",
      "न् : 16\n",
      "ए : 16\n",
      "र् : 15\n",
      "इ : 15\n",
      "ह् : 15\n",
      "ई : 15\n",
      "य् : 13\n",
      "द् : 12\n",
      "म् : 11\n",
      "प् : 10\n",
      "अं : 10\n",
      "ल् : 10\n",
      "त् : 9\n",
      "स् : 7\n",
      "ज् : 7\n",
      "ओ : 7\n",
      "उ : 5\n",
      "र्अ : 8\n",
      "य्आ : 8\n",
      "न्अ : 7\n",
      "त्अ : 7\n",
      "क्अ : 6\n",
      "स्अ : 6\n",
      "अन् : 6\n",
      "ह्अ : 5\n",
      "य्अ : 5\n",
      "अर् : 5\n",
      "आर् : 5\n",
      "ज्अ : 5\n",
      "अह् : 5\n",
      "द्अ : 4\n",
      "ल्अ : 4\n",
      "प्अ : 4\n",
      "म्ए : 4\n",
      "एअं : 4\n",
      "इय् : 3\n",
      "द्इ : 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Set containing Matra of Hindi vowels\n",
    "matra_of_vowels = {'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॄ', 'ॅ', 'े', 'ै', 'ो', 'ौ', 'ं', 'ः', 'ँ'}\n",
    "\n",
    "# Set containing Hindi vowels\n",
    "hindi_vowels = {'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ए', 'ऐ', 'ओ', 'औ', 'अं', 'अः', 'अँ'}\n",
    "\n",
    "# Set containing Hindi consonants\n",
    "hindi_consonants = {'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', \n",
    "                    'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'व', \n",
    "                    'श', 'ष', 'स', 'ह', 'क्ष', 'त्र', 'ज्ञ'}\n",
    "\n",
    "# Iterate over each word in the Hindi corpus\n",
    "glbl = []\n",
    "halant = '्'\n",
    "matras_with_vowels = {\n",
    "    'ा': 'आ',\n",
    "    'ि': 'इ',\n",
    "    'ी': 'ई',\n",
    "    'ु': 'उ',\n",
    "    'ू': 'ऊ',\n",
    "    'ृ': 'ऋ',\n",
    "    'ॄ': 'ॠ',\n",
    "    'ॅ': 'ऍ',\n",
    "    'े': 'ए',\n",
    "    'ै': 'ऐ',\n",
    "    'ो': 'ओ',\n",
    "    'ौ': 'औ',\n",
    "    'ं': 'अं',\n",
    "    'ः': 'अः',\n",
    "    'ँ': 'अँ'\n",
    "}\n",
    "letter_freq_map = {}\n",
    "letter_freq_map2 = {}\n",
    "\n",
    "# Count frequencies of letters\n",
    "\n",
    "\n",
    "# Print the frequencies\n",
    "for word in tokens:\n",
    "    \n",
    "    temp = []\n",
    "    \n",
    "    for ch in word:\n",
    "        \n",
    "        \n",
    "        if ch in hindi_consonants:\n",
    "            ch = ch + halant\n",
    "            temp.append(ch)\n",
    "            temp.append('अ')\n",
    "        elif ch in matra_of_vowels:\n",
    "            if len(temp) > 1 and temp[len(temp) - 1] == 'अ':\n",
    "                temp[len(temp) - 1] = matras_with_vowels[ch]\n",
    "            else :\n",
    "                temp.append(matras_with_vowels[ch]) \n",
    "        elif ch == halant:\n",
    "            if len(temp) >= 1:\n",
    "                temp.pop()\n",
    "            else:\n",
    "                temp.append(ch)\n",
    "        elif ch in hindi_vowels: \n",
    "            temp.append(ch)  \n",
    "        \n",
    "    # print(temp)\n",
    "    for letter in temp:\n",
    "        if letter in letter_freq_map:\n",
    "            letter_freq_map[letter] += 1\n",
    "        else:\n",
    "            letter_freq_map[letter] = 1\n",
    "            \n",
    "    for i in range(len(temp) - 1):\n",
    "        letter = temp[i] + temp[i + 1]\n",
    "        if letter in letter_freq_map2:\n",
    "            letter_freq_map2[letter] += 1\n",
    "        else:\n",
    "            letter_freq_map2[letter] = 1\n",
    "\n",
    "sorted_freq_items = sorted(letter_freq_map.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_freq_items2 = sorted(letter_freq_map2.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_freq_items = sorted_freq_items[:20]\n",
    "sorted_freq_items2 = sorted_freq_items2[:20]\n",
    "# Print the sorted frequencies\n",
    "print(\"Top 20 Unigram\")\n",
    "for letter, freq in sorted_freq_items:\n",
    "    print(letter, \":\", freq)\n",
    "print(\"Top 20 Bigram\")\n",
    "for letter, freq in sorted_freq_items2:\n",
    "    print(letter, \":\", freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['प्र'], ['इ', 'या', 'अं'], ['श'], ['उ'], ['ह'], ['्', 'य'], ['उ'], ['अं', 'द'], ['ई'], ['चा'], ['अँ'], ['द'], ['दि', 'ल'], ['च'], ['स्प'], ['क'], ['र्ण'], ['क'], ['अं', 'स'], ['हि'], ['न', '्'], ['दी'], ['मे', 'अं'], ['आ'], ['वे', 'द', 'न'], ['क', 'र', 'ने'], ['की'], ['आ', 'ख'], ['इ'], ['री'], ['त'], ['आ', 'री'], ['ख'], ['ज', 'न', 'व', 'री'], ['है'], ['इ', 'त'], ['नी'], ['दु'], ['आ'], ['क', 'र'], ['दो'], ['ह', 'मा', 'रे'], ['लि', 'ए'], ['कि'], ['ज'], ['इ', 'त'], ['ना'], ['प'], ['्', 'य'], ['आ', 'र'], ['दु', 'नि', 'या'], ['ने'], ['आ', 'प', 'को'], ['दि', 'या'], ['है'], ['ब', 'स'], ['उ'], ['त'], ['ना'], ['ही'], ['ह', 'मे', 'अं'], ['भी'], ['मि', 'ल'], ['जा', 'ए'], ['मो', 'दी'], ['स', 'र', 'का', 'र'], ['के'], ['प', 'ह', 'ले'], ['का', 'र्य'], ['का', 'ल'], ['मे', 'अं'], ['भी'], ['ती', 'न'], ['त'], ['ला'], ['क'], ['को'], ['ले', 'क', 'र'], ['बि', 'ल'], ['ला'], ['या'], ['ग', 'या'], ['था'], ['हा', 'ला', 'अं', 'कि'], ['त', 'ब'], ['य', 'ह'], ['रा', 'ज्य'], ['स', 'भा'], ['मे', 'अं'], ['पा', 'स'], ['न', 'ही', 'अं'], ['हो'], ['पा'], ['या'], ['था'], ['भा', 'ज', 'पा'], ['के'], ['दि', 'व'], ['अं', 'ग'], ['त'], ['ने', 'ता'], ['प्र'], ['मो'], ['द'], ['म', 'हा'], ['ज', 'न'], ['की'], ['बे'], ['टी'], ['पू'], ['न'], ['म'], ['म', 'हा'], ['ज', 'न'], ['को'], ['स', 'चि', 'व'], ['ब', 'ना', 'या'], ['ग', 'या'], ['है']]\n",
      "{'इया': 1, 'याअं': 1, '्य': 1, 'अंद': 1, 'दिल': 1, 'अंस': 1, 'न्': 1, 'मेअं': 1, 'वेद': 1, 'दन': 1, 'कर': 1, 'रने': 1, 'आख': 1, 'आरी': 1, 'जन': 1, 'नव': 1, 'वरी': 1, 'इत': 1, 'हमा': 1, 'मारे': 1, 'लिए': 1, 'आर': 1, 'दुनि': 1, 'निया': 1, 'आप': 1, 'पको': 1, 'दिया': 1, 'बस': 1, 'हमे': 1, 'मिल': 1, 'जाए': 1, 'मोदी': 1, 'सर': 1, 'रका': 1, 'कार': 1, 'पह': 1, 'हले': 1, 'कार्य': 1, 'काल': 1, 'तीन': 1, 'लेक': 1, 'बिल': 1, 'गया': 1, 'हाला': 1, 'लाअं': 1, 'अंकि': 1, 'तब': 1, 'यह': 1, 'राज्य': 1, 'सभा': 1, 'पास': 1, 'नही': 1, 'हीअं': 1, 'भाज': 1, 'जपा': 1, 'दिव': 1, 'अंग': 1, 'नेता': 1, 'महा': 1, 'सचि': 1, 'चिव': 1, 'बना': 1, 'नाया': 1}\n",
      "अं : 10\n",
      "या : 8\n",
      "न : 8\n",
      "त : 7\n",
      "क : 6\n",
      "स : 6\n",
      "आ : 6\n",
      "र : 6\n",
      "ह : 5\n",
      "ज : 5\n",
      "इ : 4\n",
      "द : 4\n",
      "ल : 4\n",
      "मे : 4\n",
      "उ : 3\n",
      "् : 3\n",
      "य : 3\n",
      "दि : 3\n",
      "ने : 3\n",
      "री : 3\n",
      "इया : 1\n",
      "याअं : 1\n",
      "्य : 1\n",
      "अंद : 1\n",
      "दिल : 1\n",
      "अंस : 1\n",
      "न् : 1\n",
      "मेअं : 1\n",
      "वेद : 1\n",
      "दन : 1\n",
      "कर : 1\n",
      "रने : 1\n",
      "आख : 1\n",
      "आरी : 1\n",
      "जन : 1\n",
      "नव : 1\n",
      "वरी : 1\n",
      "इत : 1\n",
      "हमा : 1\n",
      "मारे : 1\n"
     ]
    }
   ],
   "source": [
    "syllable_freq_map = {}\n",
    "bigram = {}\n",
    "syllables = []\n",
    "for word in tokens:\n",
    "    syllable = []\n",
    "    temp = []\n",
    "    for ch in word:\n",
    "        \n",
    "        if ch in hindi_consonants:\n",
    "            syllable.append(ch)\n",
    "        elif ch in matra_of_vowels:\n",
    "            if len(syllable) >= 1 and temp[len(temp) - 1] in hindi_consonants:\n",
    "                syllable[len(syllable) - 1] = syllable[len(syllable) - 1] + ch \n",
    "            else :\n",
    "                syllable.append(matras_with_vowels[ch]) \n",
    "            # print(syllable)\n",
    "        elif ch in hindi_vowels: \n",
    "            syllable.append(ch)\n",
    "        elif ch == halant:\n",
    "            syllable.append(ch)\n",
    "        \n",
    "        if(len(syllable) >= 3 and syllable[len(syllable) - 2] == halant) :\n",
    "            syllable.pop()\n",
    "            syllable.pop()\n",
    "            syllable[len(syllable) - 1] = syllable[len(syllable) - 1] + halant + ch\n",
    "        temp.append(ch)\n",
    "           \n",
    "    for syllabl in syllable:\n",
    "        if syllabl in syllable_freq_map:\n",
    "            syllable_freq_map[syllabl] += 1\n",
    "        else:\n",
    "            syllable_freq_map[syllabl] = 1\n",
    "    \n",
    "    for i in range(len(syllable) - 1):\n",
    "        \n",
    "        syllabl = syllable[i] + syllable[i + 1]\n",
    "        \n",
    "        if syllabl in syllable_freq_map:\n",
    "            bigram[syllabl] += 1\n",
    "        else:\n",
    "            bigram[syllabl] = 1\n",
    "    # print(syllable)\n",
    "    syllables.append(syllable)\n",
    "# print(syllables)    \n",
    "# print(syllable_freq_map)\n",
    "# print(bigram)\n",
    "sorted_freq_items = sorted(syllable_freq_map.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_freq_items2 = sorted(bigram.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_freq_items = sorted_freq_items[:20]\n",
    "sorted_freq_items2 = sorted_freq_items2[:20]\n",
    "\n",
    "# Print the sorted frequencies\n",
    "print(\"Top 20 Unigram Syllables\")\n",
    "for letter, freq in sorted_freq_items:\n",
    "    print(letter, \":\", freq)\n",
    "print(\"Top 20 Bigram Syllables\")\n",
    "for letter, freq in sorted_freq_items2:\n",
    "    print(letter, \":\", freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "महाजन : 2\n",
      "प्रियां : 1\n",
      "ियांश : 1\n",
      "शु : 1\n",
      "ुह : 1\n",
      "ह्य : 1\n",
      "्यु : 1\n",
      "ुंद : 1\n",
      "ंदई : 1\n",
      "ईचा : 1\n",
      "चाँ : 1\n",
      "ँद : 1\n",
      "ददिल : 1\n",
      "दिलच : 1\n",
      "चस्प : 1\n",
      "स्पक : 1\n",
      "कर्ण : 1\n",
      "र्णक : 1\n",
      "कंस : 1\n",
      "ंसहि : 1\n"
     ]
    }
   ],
   "source": [
    "bigram_token = {}\n",
    "for i in range(len(tokens) - 1):\n",
    "     tkn = tokens[i] + tokens[i + 1]\n",
    "        \n",
    "     if tkn in bigram_token:\n",
    "        bigram_token[tkn] += 1\n",
    "     else:\n",
    "        bigram_token[tkn] = 1\n",
    "sorted_freq_items = sorted(bigram_token.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_freq_items = sorted_freq_items[:20]\n",
    "# Print the sorted frequencies\n",
    "for letter, freq in sorted_freq_items:\n",
    "    print(letter, \":\", freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
