{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "matra_of_vowels = {'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॄ', 'ॅ', 'े', 'ै', 'ो', 'ौ', 'ं', 'ः', 'ँ'}\n",
    "\n",
    "# Set containing Hindi vowels\n",
    "hindi_vowels = {'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ए', 'ऐ', 'ओ', 'औ', 'अं', 'अः', 'अँ'}\n",
    "\n",
    "# Set containing Hindi consonants\n",
    "hindi_consonants = {'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', \n",
    "                    'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'व', \n",
    "                    'श', 'ष', 'स', 'ह', 'क्ष', 'त्र', 'ज्ञ'}\n",
    "halant = \"्\"\n",
    "def clean_token(tokens1):\n",
    "    tokens = []\n",
    "    for word in tokens1:\n",
    "        s=\"\"\n",
    "        for c in word:\n",
    "            if (c not in matra_of_vowels) and (c not in hindi_consonants) and (c not in hindi_vowels) and c != halant: continue\n",
    "            else: s = s + c\n",
    "        if(len(s)): tokens.append(s)\n",
    "    return tokens\n",
    "# //remove white space\n",
    "def clean_white_space(tokens):\n",
    "    ans = []\n",
    "    for token in tokens:\n",
    "        # token.lstrip()\n",
    "        ans.append(token)\n",
    "        # print(token)\n",
    "    return ans\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "# Define paths\n",
    "input_file = \"hi_100.txt\"  # Path to the text corpus file\n",
    "model_prefix = \"hindi_ug2k_model\"      # Prefix for the trained model files\n",
    "vocab_size = 2000                # Vocabulary size\n",
    "model_type = \"unigram\"            # Model type (other options: \"bpe\", \"char\", \"word\")\n",
    "\n",
    "# Train SentencePiece model\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    f\"--input={input_file} --model_prefix={model_prefix} --vocab_size={vocab_size} --model_type={model_type}\"\n",
    ")\n",
    "\n",
    "# Load trained model\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(f\"{model_prefix}.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 20 Most Freq Tokens\n",
      "के : 334803\n",
      "में : 240292\n",
      "है : 215632\n",
      "की : 207268\n",
      "न : 184136\n",
      "ी : 173237\n",
      "ने : 171964\n",
      "ल : 163999\n",
      "र : 162073\n",
      "को : 161616\n",
      "से : 159035\n",
      "का : 157794\n",
      "क : 155576\n",
      "म : 133013\n",
      "स : 126644\n",
      "ा : 117568\n",
      "और : 115376\n",
      "त : 112119\n",
      "ों : 109310\n",
      "पर : 107520\n"
     ]
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(\"hindi_ug2k_model.model\")  # Load the trained model\n",
    "\n",
    "# Define the Hindi line\n",
    "with open('hi_100.txt', 'r', encoding='utf-8') as file:\n",
    "    # Read the entire content of the file\n",
    "    hindi_corpus = file.read()\n",
    "# hindi_line = \"तुम्हारे पास क्या है?\"\n",
    "matra_of_vowels = {'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॄ', 'ॅ', 'े', 'ै', 'ो', 'ौ', 'ं', 'ः', 'ँ'}\n",
    "\n",
    "# Set containing Hindi vowels\n",
    "hindi_vowels = {'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ए', 'ऐ', 'ओ', 'औ', 'अं', 'अः', 'अँ'}\n",
    "\n",
    "# Set containing Hindi consonants\n",
    "hindi_consonants = {'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', \n",
    "                    'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'व', \n",
    "                    'श', 'ष', 'स', 'ह', 'क्ष', 'त्र', 'ज्ञ'}\n",
    "\n",
    "hindi_consonants_with_halant = {\n",
    "    'क्', 'ख्', 'ग्', 'घ्', 'च्', 'छ्', 'ज्', 'झ्', 'ट्', 'ठ्', 'ड्', 'ढ्', 'ण्',\n",
    "    'त्', 'थ्', 'द्', 'ध्', 'न्', 'प्', 'फ्', 'ब्', 'भ्', 'म्', 'य्', 'र्', 'ल्',\n",
    "    'व्', 'श्', 'ष्', 'स्', 'ह्', 'क्ष्', 'त्र्', 'ज्ञ्'\n",
    "}\n",
    "\n",
    "\n",
    "# Tokenize the Hindi line\n",
    "tokens = sp.encode_as_pieces(hindi_corpus)\n",
    "tokens = clean_token(tokens)\n",
    "\n",
    "letter_freq_map = {}\n",
    "# for letter in tokens:\n",
    "#     ltr = \"\"\n",
    "#     for ch in letter:\n",
    "#         if ch in matra_of_vowels or ch in hindi_vowels or ch in hindi_consonants or ch in hindi_consonants_with_halant or ch == halant:\n",
    "             \n",
    "for letter in tokens:\n",
    "\n",
    "    if letter in letter_freq_map:\n",
    "        letter_freq_map[letter] += 1\n",
    "    else:\n",
    "        letter_freq_map[letter] = 1\n",
    "\n",
    "sorted_freq_items = sorted(letter_freq_map.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_freq_items = sorted_freq_items[:20]\n",
    "# Print the sorted frequencies\n",
    "print(\"TOP 20 Most Freq Tokens\")\n",
    "for letter, freq in sorted_freq_items:\n",
    "    print(letter, \":\", freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Most Freq Unigrams\n",
      "अ : 8578423\n",
      "आ : 2991109\n",
      "ए : 2318442\n",
      "क् : 2221101\n",
      "र् : 2115631\n",
      "ई : 1460305\n",
      "इ : 1432973\n",
      "न् : 1334418\n",
      "स् : 1283708\n",
      "अं : 1201207\n",
      "ह् : 1133159\n",
      "म् : 1053237\n",
      "त् : 980066\n",
      "ल् : 919917\n",
      "ओ : 896588\n",
      "प् : 805896\n",
      "य् : 753228\n",
      "व् : 624743\n",
      "द् : 607633\n",
      "उ : 587149\n",
      "Top 20 Most Freq Bigrams\n",
      "र्अ : 1373877\n",
      "क्अ : 700538\n",
      "अर् : 616934\n",
      "न्अ : 612091\n",
      "स्अ : 581990\n",
      "प्अ : 457498\n",
      "त्अ : 435166\n",
      "ल्अ : 427133\n",
      "क्ए : 399726\n",
      "म्अ : 398260\n",
      "अह् : 359274\n",
      "एअं : 338170\n",
      "ह्अ : 332812\n",
      "न्ए : 321740\n",
      "य्अ : 318558\n",
      "क्आ : 307132\n",
      "आर् : 302100\n",
      "ह्ऐ : 296084\n",
      "य्आ : 291860\n",
      "म्ए : 290675\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Set containing Matra of Hindi vowels\n",
    "matra_of_vowels = {'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॄ', 'ॅ', 'े', 'ै', 'ो', 'ौ', 'ं', 'ः', 'ँ'}\n",
    "\n",
    "# Set containing Hindi vowels\n",
    "hindi_vowels = {'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ए', 'ऐ', 'ओ', 'औ', 'अं', 'अः', 'अँ'}\n",
    "\n",
    "# Set containing Hindi consonants\n",
    "hindi_consonants = {'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', \n",
    "                    'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'व', \n",
    "                    'श', 'ष', 'स', 'ह', 'क्ष', 'त्र', 'ज्ञ'}\n",
    "\n",
    "# Iterate over each word in the Hindi corpus\n",
    "glbl = []\n",
    "halant = '्'\n",
    "matras_with_vowels = {\n",
    "    'ा': 'आ',\n",
    "    'ि': 'इ',\n",
    "    'ी': 'ई',\n",
    "    'ु': 'उ',\n",
    "    'ू': 'ऊ',\n",
    "    'ृ': 'ऋ',\n",
    "    'ॄ': 'ॠ',\n",
    "    'ॅ': 'ऍ',\n",
    "    'े': 'ए',\n",
    "    'ै': 'ऐ',\n",
    "    'ो': 'ओ',\n",
    "    'ौ': 'औ',\n",
    "    'ं': 'अं',\n",
    "    'ः': 'अः',\n",
    "    'ँ': 'अँ'\n",
    "}\n",
    "letter_freq_map = {}\n",
    "letter_freq_map2 = {}\n",
    "\n",
    "# Count frequencies of letters\n",
    "\n",
    "\n",
    "# Print the frequencies\n",
    "for word in tokens:\n",
    "    \n",
    "    temp = []\n",
    "    \n",
    "    for ch in word:\n",
    "        \n",
    "        \n",
    "        if ch in hindi_consonants:\n",
    "            ch = ch + halant\n",
    "            temp.append(ch)\n",
    "            temp.append('अ')\n",
    "        elif ch in matra_of_vowels:\n",
    "            if len(temp) > 1 and temp[len(temp) - 1] == 'अ':\n",
    "                temp[len(temp) - 1] = matras_with_vowels[ch]\n",
    "            else :\n",
    "                temp.append(matras_with_vowels[ch]) \n",
    "        elif ch == halant:\n",
    "            if len(temp) >= 1:\n",
    "                temp.pop()\n",
    "            else:\n",
    "                temp.append(ch)\n",
    "        elif ch in hindi_vowels: \n",
    "            temp.append(ch)  \n",
    "        \n",
    "    # print(temp)\n",
    "    for letter in temp:\n",
    "        if letter in letter_freq_map:\n",
    "            letter_freq_map[letter] += 1\n",
    "        else:\n",
    "            letter_freq_map[letter] = 1\n",
    "            \n",
    "    for i in range(len(temp) - 1):\n",
    "        letter = temp[i] + temp[i + 1]\n",
    "        if letter in letter_freq_map2:\n",
    "            letter_freq_map2[letter] += 1\n",
    "        else:\n",
    "            letter_freq_map2[letter] = 1\n",
    "\n",
    "sorted_freq_items = sorted(letter_freq_map.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_freq_items2 = sorted(letter_freq_map2.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_freq_items = sorted_freq_items[:20]\n",
    "sorted_freq_items2 = sorted_freq_items2[:20]\n",
    "# Print the sorted frequencies\n",
    "print(\"Top 20 Most Freq Unigrams\")\n",
    "for letter, freq in sorted_freq_items:\n",
    "    print(letter, \":\", freq)\n",
    "print(\"Top 20 Most Freq Bigrams\")\n",
    "for letter, freq in sorted_freq_items2:\n",
    "    print(letter, \":\", freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 Unigram syllables\n",
      "र : 1182940\n",
      "अं : 1064967\n",
      "क : 680455\n",
      "न : 601663\n",
      "स : 580340\n",
      "ए : 464180\n",
      "इ : 444477\n",
      "प : 436349\n",
      "ल : 420833\n",
      "आ : 419870\n",
      "के : 399027\n",
      "त : 381811\n",
      "म : 362614\n",
      "ह : 329150\n",
      "ने : 321740\n",
      "ई : 307489\n",
      "का : 306198\n",
      "है : 296084\n",
      "मे : 288570\n",
      "ब : 280362\n",
      "Top 20 Bigram syllables\n",
      "र : 1182940\n",
      "अं : 1064967\n",
      "क : 680455\n",
      "न : 601663\n",
      "स : 580340\n",
      "ए : 464180\n",
      "इ : 444477\n",
      "प : 436349\n",
      "ल : 420833\n",
      "आ : 419870\n",
      "के : 399027\n",
      "त : 381811\n",
      "म : 362614\n",
      "ह : 329150\n",
      "ने : 321740\n",
      "ई : 307489\n",
      "का : 306198\n",
      "है : 296084\n",
      "मे : 288570\n",
      "ब : 280362\n"
     ]
    }
   ],
   "source": [
    "syllable_freq_map = {}\n",
    "bigram = {}\n",
    "syllables = []\n",
    "for word in tokens:\n",
    "    syllable = []\n",
    "    temp = []\n",
    "    for ch in word:\n",
    "        \n",
    "        if ch in hindi_consonants:\n",
    "            syllable.append(ch)\n",
    "        elif ch in matra_of_vowels:\n",
    "            if len(syllable) >= 1 and temp[len(temp) - 1] in hindi_consonants:\n",
    "                syllable[len(syllable) - 1] = syllable[len(syllable) - 1] + ch \n",
    "            else :\n",
    "                syllable.append(matras_with_vowels[ch]) \n",
    "            # print(syllable)\n",
    "        elif ch in hindi_vowels: \n",
    "            syllable.append(ch)\n",
    "        elif ch == halant:\n",
    "            syllable.append(ch)\n",
    "        \n",
    "        if(len(syllable) >= 3 and syllable[len(syllable) - 2] == halant) :\n",
    "            syllable.pop()\n",
    "            syllable.pop()\n",
    "            syllable[len(syllable) - 1] = syllable[len(syllable) - 1] + halant + ch\n",
    "        temp.append(ch)\n",
    "           \n",
    "    for syllabl in syllable:\n",
    "        if syllabl in syllable_freq_map:\n",
    "            syllable_freq_map[syllabl] += 1\n",
    "        else:\n",
    "            syllable_freq_map[syllabl] = 1\n",
    "    \n",
    "    for i in range(len(syllable) - 1):\n",
    "        \n",
    "        syllabl = syllable[i] + syllable[i + 1]\n",
    "        \n",
    "        if syllabl in syllable_freq_map:\n",
    "            bigram[syllabl] += 1\n",
    "        else:\n",
    "            bigram[syllabl] = 1\n",
    "    # print(syllable)\n",
    "    syllables.append(syllable)\n",
    "# print(syllables)    \n",
    "# print(syllable_freq_map)\n",
    "# print(bigram)\n",
    "sorted_freq_items = sorted(syllable_freq_map.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_freq_items = sorted_freq_items[:20]\n",
    "sorted_freq_items2 = sorted(bigram.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_freq_items2 = sorted_freq_items[:20]\n",
    "# Print the sorted frequencies\n",
    "\n",
    "print(\"Top 20 Unigram syllables\")\n",
    "for letter, freq in sorted_freq_items:\n",
    "    print(letter, \":\", freq)\n",
    "    \n",
    "print(\"Top 20 Bigram syllables\")\n",
    "for letter, freq in sorted_freq_items2:\n",
    "    print(letter, \":\", freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Print' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m sorted_freq_items \u001b[38;5;241m=\u001b[39m sorted_freq_items[:\u001b[38;5;241m20\u001b[39m]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Print the sorted frequencies\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mPrint\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTop 20 Bigram Tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m letter, freq \u001b[38;5;129;01min\u001b[39;00m sorted_freq_items:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(letter, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m, freq)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Print' is not defined"
     ]
    }
   ],
   "source": [
    "bigram_token = {}\n",
    "for i in range(len(tokens) - 1):\n",
    "     tkn = tokens[i] + tokens[i + 1]\n",
    "        \n",
    "     if tkn in bigram_token:\n",
    "        bigram_token[tkn] += 1\n",
    "     else:\n",
    "        bigram_token[tkn] = 1\n",
    "sorted_freq_items = sorted(bigram_token.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_freq_items = sorted_freq_items[:20]\n",
    "# Print the sorted frequencies\n",
    "Print(\"Top 20 Bigram Tokens\")\n",
    "for letter, freq in sorted_freq_items:\n",
    "    print(letter, \":\", freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
