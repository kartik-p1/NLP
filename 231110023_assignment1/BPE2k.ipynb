{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "matra_of_vowels = {'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॄ', 'ॅ', 'े', 'ै', 'ो', 'ौ', 'ं', 'ः', 'ँ'}\n",
    "\n",
    "# Set containing Hindi vowels\n",
    "hindi_vowels = {'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ए', 'ऐ', 'ओ', 'औ', 'अं', 'अः', 'अँ'}\n",
    "\n",
    "# Set containing Hindi consonants\n",
    "hindi_consonants = {'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', \n",
    "                    'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'व', \n",
    "                    'श', 'ष', 'स', 'ह', 'क्ष', 'त्र', 'ज्ञ'}\n",
    "halant = \"्\"\n",
    "def clean_token(tokens1):\n",
    "    tokens = []\n",
    "    for word in tokens1:\n",
    "        s=\"\"\n",
    "        for c in word:\n",
    "            if (c not in matra_of_vowels) and (c not in hindi_consonants) and (c not in hindi_vowels) and c != halant: continue\n",
    "            else: s = s + c\n",
    "        if(len(s)): tokens.append(s)\n",
    "    return tokens\n",
    "# //remove white space\n",
    "def clean_white_space(tokens):\n",
    "    ans = []\n",
    "    for token in tokens:\n",
    "        # token.lstrip()\n",
    "        ans.append(token)\n",
    "        # print(token)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "# Path to your corpus\n",
    "corpus_file = \"hi_100.txt\"\n",
    "\n",
    "# Path to save the trained model\n",
    "model_prefix = \"hindi_bpe_model\"\n",
    "\n",
    "# Define the parameters for training the BPE model\n",
    "vocab_size = 2000  # You can adjust this based on your corpus size and requirements\n",
    "model_type = \"bpe\"  # BPE model type\n",
    "\n",
    "# Train the BPE model\n",
    "spm.SentencePieceTrainer.train(input=corpus_file, model_prefix=model_prefix, vocab_size=vocab_size, model_type=model_type)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(\"hindi_bpe_model.model\")  # Load the trained model\n",
    "\n",
    "# Define the Hindi line\n",
    "with open('demo_hindi.txt', 'r', encoding='utf-8') as file:\n",
    "    # Read the entire content of the file\n",
    "    hindi_corpus = file.read()\n",
    "\n",
    "# Tokenize the Hindi line\n",
    "tokens = sp.EncodeAsPieces(hindi_corpus)\n",
    "tokens = clean_token(tokens)\n",
    "# print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "त : 4\n",
      "क : 3\n",
      "में : 3\n",
      "है : 3\n",
      "प्र : 2\n",
      "ु : 2\n",
      "्य : 2\n",
      "द : 2\n",
      "आ : 2\n",
      "की : 2\n",
      "ना : 2\n",
      "भी : 2\n",
      "के : 2\n",
      "ला : 2\n",
      "को : 2\n",
      "या : 2\n",
      "गया : 2\n",
      "था : 2\n",
      "महा : 2\n",
      "जन : 2\n"
     ]
    }
   ],
   "source": [
    "letter_freq_map = {}\n",
    "tokens = clean_token(tokens)\n",
    "for letter in tokens:\n",
    "\n",
    "    if letter in letter_freq_map:\n",
    "        letter_freq_map[letter] += 1\n",
    "    else:\n",
    "        letter_freq_map[letter] = 1\n",
    "\n",
    "sorted_freq_items = sorted(letter_freq_map.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_freq_items = sorted_freq_items[:20]\n",
    "# Print the sorted frequencies\n",
    "for letter, freq in sorted_freq_items:\n",
    "    print(letter, \":\", freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 20 unigrams\n",
      "अ : 78\n",
      "आ : 38\n",
      "क् : 18\n",
      "न् : 16\n",
      "ए : 16\n",
      "र् : 15\n",
      "इ : 15\n",
      "ह् : 15\n",
      "ई : 15\n",
      "य् : 13\n",
      "द् : 12\n",
      "म् : 11\n",
      "प् : 10\n",
      "अं : 10\n",
      "ल् : 10\n",
      "त् : 9\n",
      "स् : 7\n",
      "ज् : 7\n",
      "ओ : 7\n",
      "उ : 5\n",
      "top 20 bigrams\n",
      "र्अ : 8\n",
      "य्आ : 8\n",
      "न्अ : 7\n",
      "त्अ : 7\n",
      "क्अ : 6\n",
      "स्अ : 6\n",
      "अन् : 6\n",
      "ह्अ : 5\n",
      "य्अ : 5\n",
      "अर् : 5\n",
      "आर् : 5\n",
      "ज्अ : 5\n",
      "अह् : 5\n",
      "द्अ : 4\n",
      "ल्अ : 4\n",
      "प्अ : 4\n",
      "म्ए : 4\n",
      "एअं : 4\n",
      "इय् : 3\n",
      "द्इ : 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Set containing Matra of Hindi vowels\n",
    "matra_of_vowels = {'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॄ', 'ॅ', 'े', 'ै', 'ो', 'ौ', 'ं', 'ः', 'ँ'}\n",
    "\n",
    "# Set containing Hindi vowels\n",
    "hindi_vowels = {'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ए', 'ऐ', 'ओ', 'औ', 'अं', 'अः', 'अँ'}\n",
    "\n",
    "# Set containing Hindi consonants\n",
    "hindi_consonants = {'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', \n",
    "                    'त', 'थ', 'द', 'ध', 'न', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ल', 'व', \n",
    "                    'श', 'ष', 'स', 'ह', 'क्ष', 'त्र', 'ज्ञ'}\n",
    "\n",
    "# Iterate over each word in the Hindi corpus\n",
    "glbl = []\n",
    "halant = '्'\n",
    "matras_with_vowels = {\n",
    "    'ा': 'आ',\n",
    "    'ि': 'इ',\n",
    "    'ी': 'ई',\n",
    "    'ु': 'उ',\n",
    "    'ू': 'ऊ',\n",
    "    'ृ': 'ऋ',\n",
    "    'ॄ': 'ॠ',\n",
    "    'ॅ': 'ऍ',\n",
    "    'े': 'ए',\n",
    "    'ै': 'ऐ',\n",
    "    'ो': 'ओ',\n",
    "    'ौ': 'औ',\n",
    "    'ं': 'अं',\n",
    "    'ः': 'अः',\n",
    "    'ँ': 'अँ'\n",
    "}\n",
    "letter_freq_map = {}\n",
    "letter_freq_map2 = {}\n",
    "\n",
    "# Count frequencies of letters\n",
    "\n",
    "\n",
    "# Print the frequencies\n",
    "for word in tokens:\n",
    "    \n",
    "    temp = []\n",
    "    \n",
    "    for ch in word:\n",
    "        \n",
    "        \n",
    "        if ch in hindi_consonants:\n",
    "            ch = ch + halant\n",
    "            temp.append(ch)\n",
    "            temp.append('अ')\n",
    "        elif ch in matra_of_vowels:\n",
    "            if len(temp) > 1 and temp[len(temp) - 1] == 'अ':\n",
    "                temp[len(temp) - 1] = matras_with_vowels[ch]\n",
    "            else :\n",
    "                temp.append(matras_with_vowels[ch]) \n",
    "        elif ch == halant:\n",
    "            if len(temp) >= 1:\n",
    "                temp.pop()\n",
    "            else:\n",
    "                temp.append(ch)\n",
    "        elif ch in hindi_vowels: \n",
    "            temp.append(ch)  \n",
    "        \n",
    "    # print(temp)\n",
    "    for letter in temp:\n",
    "        if letter in letter_freq_map:\n",
    "            letter_freq_map[letter] += 1\n",
    "        else:\n",
    "            letter_freq_map[letter] = 1\n",
    "            \n",
    "    for i in range(len(temp) - 1):\n",
    "        letter = temp[i] + temp[i + 1]\n",
    "        if letter in letter_freq_map2:\n",
    "            letter_freq_map2[letter] += 1\n",
    "        else:\n",
    "            letter_freq_map2[letter] = 1\n",
    "\n",
    "sorted_freq_items = sorted(letter_freq_map.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_freq_items2 = sorted(letter_freq_map2.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_freq_items = sorted_freq_items[:20]\n",
    "sorted_freq_items2 = sorted_freq_items2[:20]\n",
    "# Print the sorted frequencies\n",
    "print(\"top 20 unigrams\")\n",
    "for letter, freq in sorted_freq_items:\n",
    "    print(letter, \":\", freq)\n",
    "print(\"top 20 bigrams\")\n",
    "for letter, freq in sorted_freq_items2:\n",
    "    print(letter, \":\", freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 unigrams syllable\n",
      "अं : 10\n",
      "या : 8\n",
      "न : 8\n",
      "त : 7\n",
      "क : 6\n",
      "स : 6\n",
      "आ : 6\n",
      "र : 6\n",
      "ह : 5\n",
      "ज : 5\n",
      "इ : 4\n",
      "द : 4\n",
      "ल : 4\n",
      "मे : 4\n",
      "उ : 3\n",
      "् : 3\n",
      "य : 3\n",
      "दि : 3\n",
      "ने : 3\n",
      "री : 3\n",
      "Top 20 bigrams syllable\n",
      "इया : 1\n",
      "याअं : 1\n",
      "्य : 1\n",
      "अंद : 1\n",
      "दिल : 1\n",
      "अंस : 1\n",
      "न् : 1\n",
      "मेअं : 1\n",
      "वेद : 1\n",
      "दन : 1\n",
      "कर : 1\n",
      "रने : 1\n",
      "आख : 1\n",
      "आरी : 1\n",
      "जन : 1\n",
      "नव : 1\n",
      "वरी : 1\n",
      "इत : 1\n",
      "हमा : 1\n",
      "मारे : 1\n"
     ]
    }
   ],
   "source": [
    "syllable_freq_map = {}\n",
    "bigram = {}\n",
    "syllables = []\n",
    "for word in tokens:\n",
    "    syllable = []\n",
    "    temp = []\n",
    "    for ch in word:\n",
    "        \n",
    "        if ch in hindi_consonants:\n",
    "            syllable.append(ch)\n",
    "        elif ch in matra_of_vowels:\n",
    "            if len(syllable) >= 1 and temp[len(temp) - 1] in hindi_consonants:\n",
    "                syllable[len(syllable) - 1] = syllable[len(syllable) - 1] + ch \n",
    "            else :\n",
    "                syllable.append(matras_with_vowels[ch]) \n",
    "            # print(syllable)\n",
    "        elif ch in hindi_vowels: \n",
    "            syllable.append(ch)\n",
    "        elif ch == halant:\n",
    "            syllable.append(ch)\n",
    "        \n",
    "        if(len(syllable) >= 3 and syllable[len(syllable) - 2] == halant) :\n",
    "            syllable.pop()\n",
    "            syllable.pop()\n",
    "            syllable[len(syllable) - 1] = syllable[len(syllable) - 1] + halant + ch\n",
    "        temp.append(ch)\n",
    "           \n",
    "    for syllabl in syllable:\n",
    "        if syllabl in syllable_freq_map:\n",
    "            syllable_freq_map[syllabl] += 1\n",
    "        else:\n",
    "            syllable_freq_map[syllabl] = 1\n",
    "    \n",
    "    for i in range(len(syllable) - 1):\n",
    "        \n",
    "        syllabl = syllable[i] + syllable[i + 1]\n",
    "        \n",
    "        if syllabl in syllable_freq_map:\n",
    "            bigram[syllabl] += 1\n",
    "        else:\n",
    "            bigram[syllabl] = 1\n",
    "    # print(syllable)\n",
    "    syllables.append(syllable)\n",
    "# print(syllables)    \n",
    "# # print(syllable_freq_map)\n",
    "# print(bigram)\n",
    "sorted_freq_items = sorted(syllable_freq_map.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_freq_items2 = sorted(bigram.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_freq_items = sorted_freq_items[:20]\n",
    "sorted_freq_items2 = sorted_freq_items2[:20]\n",
    "\n",
    "# Print the sorted frequencies\n",
    "print(\"Top 20 unigrams syllable\")\n",
    "for letter, freq in sorted_freq_items:\n",
    "    print(letter, \":\", freq)\n",
    "print(\"Top 20 bigrams syllable\")\n",
    "for letter, freq in sorted_freq_items2:\n",
    "    print(letter, \":\", freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 bigram tokens\n",
      "महाजन : 2\n",
      "प्रियां : 1\n",
      "ियांश : 1\n",
      "शु : 1\n",
      "ुह : 1\n",
      "ह्य : 1\n",
      "्यु : 1\n",
      "ुंद : 1\n",
      "ंदई : 1\n",
      "ईचा : 1\n",
      "चाँ : 1\n",
      "ँद : 1\n",
      "ददिल : 1\n",
      "दिलच : 1\n",
      "चस्प : 1\n",
      "स्पक : 1\n",
      "कर्ण : 1\n",
      "र्णक : 1\n",
      "कंस : 1\n",
      "ंसहि : 1\n"
     ]
    }
   ],
   "source": [
    "bigram_token = {}\n",
    "for i in range(len(tokens) - 1):\n",
    "     tkn = tokens[i] + tokens[i + 1]\n",
    "        \n",
    "     if tkn in bigram_token:\n",
    "        bigram_token[tkn] += 1\n",
    "     else:\n",
    "        bigram_token[tkn] = 1\n",
    "sorted_freq_items = sorted(bigram_token.items(), key=lambda x: x[1], reverse=True)\n",
    "sorted_freq_items = sorted_freq_items[:20]\n",
    "# Print the sorted frequencies\n",
    "print(\"Top 20 bigram tokens\")\n",
    "for letter, freq in sorted_freq_items:\n",
    "    print(letter, \":\", freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
